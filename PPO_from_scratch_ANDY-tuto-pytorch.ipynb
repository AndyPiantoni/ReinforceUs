{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from IPython import display\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# check and use GPU if available if not use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from torch.distributions import MultivariateNormal, Normal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContinuousActor(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_dim: int, \n",
    "        out_dim: int, \n",
    "    ):\n",
    "        \"\"\"Initialize.\"\"\"\n",
    "        super(ContinuousActor, self).__init__()\n",
    "\n",
    "        self.hidden = nn.Linear(in_dim, 32)\n",
    "        self.mu_layer = nn.Linear(32, out_dim)\n",
    "        self.log_std_layer = nn.Linear(32, out_dim)\n",
    "\n",
    "    def forward(self, state: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward method implementation.\"\"\"\n",
    "        x = F.relu(self.hidden(state))\n",
    "        \n",
    "        mu = torch.tanh(self.mu_layer(x))\n",
    "        log_std = torch.tanh(self.log_std_layer(x))\n",
    "\n",
    "        std = torch.exp(log_std)\n",
    "        dist = Normal(mu, std)\n",
    "        action = dist.sample()\n",
    "\n",
    "        return action, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_actor = ContinuousActor(3, 1)\n",
    "action, dist = test_actor.forward(torch.tensor([1, 2, 3], dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE from another notebook\n",
    "class NeuralNet(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size, activation, layers=[32,32,16]):\n",
    "        super().__init__()\n",
    "\n",
    "        # Define layers with ReLU activation\n",
    "        self.linear1 = torch.nn.Linear(input_size, layers[0])\n",
    "        self.activation1 = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(layers[0], layers[1])\n",
    "        self.activation2 = torch.nn.ReLU()\n",
    "        self.linear3 = torch.nn.Linear(layers[1], layers[2])\n",
    "        self.activation3 = torch.nn.ReLU()\n",
    "\n",
    "        self.output_layer = torch.nn.Linear(layers[2], output_size)\n",
    "        self.output_activation = activation\n",
    "\n",
    "        # Initialization using Xavier normal (a popular technique for initializing weights in NNs)\n",
    "        torch.nn.init.xavier_normal_(self.linear1.weight)\n",
    "        torch.nn.init.xavier_normal_(self.linear2.weight)\n",
    "        torch.nn.init.xavier_normal_(self.linear3.weight)\n",
    "        torch.nn.init.xavier_normal_(self.output_layer.weight)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Forward pass through the layers\n",
    "        x = self.activation1(self.linear1(inputs))\n",
    "        x = self.activation2(self.linear2(x))\n",
    "        x = self.activation3(self.linear3(x))\n",
    "        x = self.output_activation(self.output_layer(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "def generate_single_episode(env, policy_net):\n",
    "    \"\"\"\n",
    "    Generates an episode by executing the current policy in the given env\n",
    "    \"\"\"\n",
    "    states = []\n",
    "    actions = []\n",
    "    rewards = []\n",
    "    log_probs = []\n",
    "    max_t = 1000 # max horizon within one episode\n",
    "    state, _ = env.reset()\n",
    "\n",
    "    if isinstance(env.action_space, gym.spaces.Box):\n",
    "        max_possible_action = float(env.action_space.high[0]) # Only works with a action space dim of 1\n",
    "        min_possible_action = float(env.action_space.low[0]) # Only works with a action space dim of 1\n",
    "\n",
    "    for t in range(max_t):\n",
    "        #print(t)\n",
    "        if isinstance(env.action_space, gym.spaces.Discrete):\n",
    "            state = torch.from_numpy(state).float().unsqueeze(0)\n",
    "        else:\n",
    "            state = torch.from_numpy(state.flatten()).float()\n",
    "            \n",
    "\n",
    "        # if action space is discrete or continuous\n",
    "        if isinstance(env.action_space, gym.spaces.Discrete):\n",
    "            probs = policy_net.forward(Variable(state)) # get each action choice probability with the current policy network\n",
    "            action = np.random.choice(env.action_space.n, p=np.squeeze(probs.detach().numpy())) # probablistic\n",
    "        else:\n",
    "            action, dist = policy_net.forward(state) # continuous\n",
    "            # clip action to the action space\n",
    "            action = torch.clamp(action, min=min_possible_action, max=max_possible_action)\n",
    "            probs = dist\n",
    "\n",
    "\n",
    "        # compute the log_prob to use this in parameter update\n",
    "        log_prob = None\n",
    "        if isinstance(env.action_space, gym.spaces.Discrete):\n",
    "            log_prob = torch.log(probs.squeeze(0)[action])\n",
    "        else:\n",
    "            log_prob = dist.log_prob(torch.tensor([action]))\n",
    "            # print(f\"log_prob: {log_prob}\")\n",
    "            \n",
    "        #print(log_prob)\n",
    "        \n",
    "        # append values\n",
    "        states.append(state)\n",
    "        actions.append(action)\n",
    "        log_probs.append(log_prob)\n",
    "        \n",
    "        # take a selected action\n",
    "        if isinstance(env.action_space, gym.spaces.Discrete):\n",
    "            state, reward, terminated, truncated, _ = env.step(action)\n",
    "        else:\n",
    "            state, reward, terminated, truncated, _ = env.step([action])\n",
    "        rewards.append(reward)\n",
    "\n",
    "        if terminated | truncated:\n",
    "            break\n",
    "            \n",
    "    return states, actions, rewards, log_probs\n",
    "\n",
    "\n",
    "def evaluate_policy(env, policy_net):\n",
    "    \"\"\"\n",
    "    Compute accumulative trajectory reward\n",
    "    \"\"\"\n",
    "    states, actions, rewards, log_probs = generate_single_episode(env, policy_net)\n",
    "    return np.sum(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_PPO(env, policy_net, policy_optimizer, value_net, value_optimizer, num_epochs, clip_val=0.2, gamma=0.99, entropy_coef=0.005, lamda=0.95):\n",
    "    \"\"\"\n",
    "    Trains the policy network using PPO\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate an episode with the current policy network\n",
    "    states, actions, rewards, log_probs = generate_single_episode(env, policy_net)\n",
    "    T = len(states)\n",
    "    \n",
    "    # Create tensors depending on if it is discrete or continuous action space\n",
    "    if isinstance(env.action_space, gym.spaces.Discrete):\n",
    "        actions = torch.LongTensor(actions).to(device).view(-1,1)\n",
    "    else:\n",
    "        actions = torch.FloatTensor(actions).to(device).view(-1,1)\n",
    "\n",
    "\n",
    "    states = np.vstack(states).astype(float)\n",
    "    states = torch.FloatTensor(states).to(device)\n",
    "    rewards = torch.FloatTensor(rewards).to(device).view(-1,1)\n",
    "    log_probs = torch.FloatTensor(log_probs).to(device).view(-1,1)\n",
    "\n",
    "    # Compute the generalized advantage estimate\n",
    "    Gs = []\n",
    "    G = 0\n",
    "    for t in range(T-1,-1,-1):\n",
    "        delta = (rewards[t] + gamma*value_net(states[t]) - value_net(states[t-1]))\n",
    "        G = delta + gamma * G * lamda\n",
    "        Gs.insert(0,G)\n",
    "    Gs = torch.tensor(Gs).view(-1,1)\n",
    "    # for t in range(T-1,-1,-1): # iterate in backward order to make the computation easier\n",
    "    #     G = rewards[t] + gamma*G\n",
    "    #     Gs.insert(0,G)\n",
    "    # Gs = torch.tensor(Gs).view(-1,1)\n",
    "    \n",
    "    # Compute the advantage\n",
    "    state_vals = value_net(states).to(device)\n",
    "    with torch.no_grad():\n",
    "        A_k = Gs - state_vals\n",
    "        \n",
    "    for _ in range(num_epochs):\n",
    "        # Compute the value of the current states\n",
    "        V = value_net(states).to(device)\n",
    "\n",
    "\n",
    "        # Calculate probability of each action under the updated policy\n",
    "        # compute the log_prob to use it in parameter update\n",
    "        if isinstance(env.action_space, gym.spaces.Discrete):\n",
    "            probs = policy_net.forward(states).to(device)\n",
    "            curr_log_probs = torch.log(torch.gather(probs, 1, actions))\n",
    "            # print(f\"probs, discrete: {probs}\")\n",
    "        else:\n",
    "            _, probs = policy_net.forward(states)\n",
    "            curr_log_probs = probs.log_prob(actions)\n",
    "            # print(f\"probs, continuous: {probs}\")\n",
    "\n",
    "        # Calculate ratios r(theta)\n",
    "        ratios = torch.exp(curr_log_probs - log_probs)\n",
    "        \n",
    "        # Calculate two surrogate loss terms in cliped loss\n",
    "        surr1 = ratios * A_k\n",
    "        surr2 = torch.clamp(ratios, 1-clip_val, 1+clip_val) * A_k\n",
    "        \n",
    "        # entropy \n",
    "        if not isinstance(env.action_space, gym.spaces.Discrete):\n",
    "            entropy = probs.entropy().mean()\n",
    "            actor_loss = (-torch.min(surr1, surr2).mean() - entropy_coef * entropy)\n",
    "        else:\n",
    "            # Calculate clipped loss value\n",
    "            actor_loss = (-torch.min(surr1, surr2)).mean() # Need negative sign to run Gradient Ascent\n",
    "        \n",
    "        # Update policy network\n",
    "        policy_optimizer.zero_grad()\n",
    "        actor_loss.backward(retain_graph=True)\n",
    "        policy_optimizer.step()\n",
    "        \n",
    "        # Update value net\n",
    "        critic_loss = nn.MSELoss()(V, Gs)\n",
    "        value_optimizer.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        value_optimizer.step()\n",
    "        \n",
    "    return policy_net, value_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lisas\\miniconda3\\envs\\Reinforce\\Lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "c:\\Users\\lisas\\miniconda3\\envs\\Reinforce\\Lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:246: UserWarning: \u001b[33mWARN: The reward returned by `step()` must be a float, int, np.integer or np.floating, actual type: <class 'numpy.ndarray'>\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\lisas\\AppData\\Local\\Temp\\ipykernel_23292\\1337364915.py:19: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:277.)\n",
      "  rewards = torch.FloatTensor(rewards).to(device).view(-1,1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0\n",
      "The avg. test reward for episode 0 is -1356.1091552734374 with std of 269.3435340058052.\n",
      "Episode: 50\n",
      "The avg. test reward for episode 50 is -1328.7388671875 with std of 246.68409680605743.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:29<00:00, 29.95s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'PPO Learning Curve')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define parameter values\n",
    "# env_name = 'CartPole-v0' # environment name\n",
    "env_name = 'Pendulum-v1' # environment name\n",
    "\n",
    "#env_name = 'LunarLander-v2' # environment name\n",
    "# env_name = 'MountainCar-v0' # environment name\n",
    "#env_name = 'Acrobot-v1' # environment name\n",
    "\n",
    "\n",
    "num_train_ite = 100 # number of training iterations\n",
    "num_seeds = 1 # fit model with 3 different seeds and plot average performance of 3 seeds\n",
    "num_epochs = 10 # how many times we iterate the entire training dataset passing through the training\n",
    "eval_freq = 50 # run evaluation of policy at each eval_freq trials\n",
    "eval_epi_index = num_train_ite//eval_freq # use to create x label for plot\n",
    "returns = np.zeros((num_seeds, eval_epi_index))\n",
    "gamma = 0.9 # discount factor\n",
    "clip_val = 0.2 # hyperparameter epsilon in clip objective\n",
    "entropy_coef = 0.005 # hyperparameter entropy coefficient \n",
    "\n",
    "# Create the environment.\n",
    "env = gym.make(env_name)\n",
    "\n",
    "#detect if the environment is discrete or continuous\n",
    "if isinstance(env.action_space, gym.spaces.Discrete):\n",
    "    nA = env.action_space.n\n",
    "else:\n",
    "    nA = env.action_space.shape[0]\n",
    "\n",
    "# detect if the environment state is discrete or continuous\n",
    "if isinstance(env.observation_space, gym.spaces.Discrete):\n",
    "    nS = env.observation_space.n\n",
    "else:\n",
    "    nS = env.observation_space.shape[0]\n",
    "\n",
    "policy_lr = 1e-4 # policy network's learning rate \n",
    "baseline_lr = 5e-4 # value network's learning rate\n",
    " \n",
    "for i in tqdm.tqdm(range(num_seeds)):\n",
    "    reward_means = []\n",
    "\n",
    "    # Define policy and value networks\n",
    "    if isinstance(env.action_space, gym.spaces.Discrete):\n",
    "        policy_net = NeuralNet(nS, nA, torch.nn.Softmax()) # Normally this one works with CartPole-v0\n",
    "    else:\n",
    "        #policy_net = NeuralNet(nS, nA, torch.nn.Identity())\n",
    "        policy_net = ContinuousActor(nS, nA)\n",
    "    policy_net_optimizer = optim.Adam(policy_net.parameters(), lr=policy_lr)\n",
    "    value_net = NeuralNet(nS, 1, torch.nn.ReLU())\n",
    "    value_net_optimizer = optim.Adam(value_net.parameters(), lr=baseline_lr)\n",
    "    \n",
    "    for m in range(num_train_ite):\n",
    "        # Train networks with PPO\n",
    "        policy_net, value_net = train_PPO(env, policy_net, policy_net_optimizer, value_net, value_net_optimizer, num_epochs, clip_val=clip_val, gamma=gamma, entropy_coef=entropy_coef)\n",
    "        if m % eval_freq == 0:\n",
    "            print(\"Episode: {}\".format(m))\n",
    "            G = np.zeros(20)\n",
    "            for k in range(20):\n",
    "                g = evaluate_policy(env, policy_net)\n",
    "                G[k] = g\n",
    "\n",
    "            reward_mean = G.mean()\n",
    "            reward_sd = G.std()\n",
    "            print(\"The avg. test reward for episode {0} is {1} with std of {2}.\".format(m, reward_mean, reward_sd))\n",
    "            reward_means.append(reward_mean)\n",
    "    returns[i] = np.array(reward_means)\n",
    "\n",
    "# save the policy network\n",
    "torch.save(policy_net.state_dict(), f\"policy_net_{env_name}.pt\")\n",
    "\n",
    "\n",
    "# Plot the performance over iterations\n",
    "x = np.arange(eval_epi_index)*eval_freq\n",
    "avg_returns = np.mean(returns, axis=0)\n",
    "max_returns = np.max(returns, axis=0)\n",
    "min_returns = np.min(returns, axis=0)\n",
    "\n",
    "plt.fill_between(x, min_returns, max_returns, alpha=0.1)\n",
    "plt.plot(x, avg_returns, '-o', markersize=1)\n",
    "\n",
    "plt.xlabel('Episode', fontsize = 15)\n",
    "plt.ylabel('Return', fontsize = 15)\n",
    "\n",
    "plt.title(\"PPO Learning Curve\", fontsize = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate_policy(env, policy_net, render=False):\n",
    "#     \"\"\"\n",
    "#     Compute accumulative trajectory reward\n",
    "#     \"\"\"\n",
    "#     state, _ = env.reset()\n",
    "#     rewards = []\n",
    "#     truncated = False\n",
    "#     done = False\n",
    "#     while not done and not truncated:\n",
    "#         if isinstance(env.action_space, gym.spaces.Discrete):\n",
    "#             state = torch.from_numpy(state).float().unsqueeze(0)\n",
    "#             probs = policy_net.forward(Variable(state)) # get each action choice probability with the current policy network\n",
    "#             action = np.random.choice(env.action_space.n, p=np.squeeze(probs.detach().numpy())) # probablistic\n",
    "            \n",
    "#             next_state, reward, done, truncated, _ = env.step(action)\n",
    "#         else:\n",
    "#             state = torch.from_numpy(state.flatten()).float()\n",
    "#             action, dist = policy_net.forward(state) # continuous\n",
    "#             print(f\"action: {action}\")\n",
    "#             next_state, reward, done, truncated, _ = env.step([action])\n",
    "#         state = next_state\n",
    "#         rewards.append(reward)\n",
    "#         if render:\n",
    "#             env.render()\n",
    "#     return np.sum(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_actor: (tensor([3.3453]), Normal(loc: tensor([0.7896], grad_fn=<TanhBackward0>), scale: tensor([2.4224], grad_fn=<ExpBackward0>)))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lisas\\miniconda3\\envs\\Reinforce\\Lib\\site-packages\\gymnasium\\envs\\classic_control\\pendulum.py:213: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  c = pygame.math.Vector2(c).rotate_rad(self.state[0] + np.pi / 2)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "size must be two numbers",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m action \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(action, \u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# take a selected action\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m state, reward, done, truncated, _ \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43maction\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m done \u001b[38;5;129;01mor\u001b[39;00m truncated:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lisas\\miniconda3\\envs\\Reinforce\\Lib\\site-packages\\gymnasium\\wrappers\\time_limit.py:57\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m     47\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m \n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[1;32mc:\\Users\\lisas\\miniconda3\\envs\\Reinforce\\Lib\\site-packages\\gymnasium\\wrappers\\order_enforcing.py:56\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lisas\\miniconda3\\envs\\Reinforce\\Lib\\site-packages\\gymnasium\\wrappers\\env_checker.py:49\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_step:\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43menv_step_passive_checker\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "File \u001b[1;32mc:\\Users\\lisas\\miniconda3\\envs\\Reinforce\\Lib\\site-packages\\gymnasium\\utils\\passive_env_checker.py:208\u001b[0m, in \u001b[0;36menv_step_passive_checker\u001b[1;34m(env, action)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"A passive check for the environment step, investigating the returning data then returning the data unchanged.\"\"\"\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;66;03m# We don't check the action as for some environments then out-of-bounds values can be given\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    210\u001b[0m     result, \u001b[38;5;28mtuple\u001b[39m\n\u001b[0;32m    211\u001b[0m ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpects step result to be a tuple, actual type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(result)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\lisas\\miniconda3\\envs\\Reinforce\\Lib\\site-packages\\gymnasium\\envs\\classic_control\\pendulum.py:143\u001b[0m, in \u001b[0;36mPendulumEnv.step\u001b[1;34m(self, u)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([newth, newthdot])\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 143\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_obs(), \u001b[38;5;241m-\u001b[39mcosts, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m, {}\n",
      "File \u001b[1;32mc:\\Users\\lisas\\miniconda3\\envs\\Reinforce\\Lib\\site-packages\\gymnasium\\envs\\classic_control\\pendulum.py:237\u001b[0m, in \u001b[0;36mPendulumEnv.render\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    235\u001b[0m img \u001b[38;5;241m=\u001b[39m pygame\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mload(fname)\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_u \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 237\u001b[0m     scale_img \u001b[38;5;241m=\u001b[39m \u001b[43mpygame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msmoothscale\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43mscale\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_u\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_u\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    241\u001b[0m     is_flip \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_u \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    242\u001b[0m     scale_img \u001b[38;5;241m=\u001b[39m pygame\u001b[38;5;241m.\u001b[39mtransform\u001b[38;5;241m.\u001b[39mflip(scale_img, is_flip, \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: size must be two numbers"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#create an environment to test and visualize the policy\n",
    "# env_name = 'CartPole-v0' # environment name\n",
    "env_name = 'Pendulum-v1' # environment name\n",
    "# env_name = 'MountainCar-v0' # environment name\n",
    "env = gym.make(env_name, render_mode='human')\n",
    "\n",
    "if isinstance(env.action_space, gym.spaces.Discrete):\n",
    "    nS = env.observation_space.shape[0]\n",
    "    nA = env.action_space.n\n",
    "    policy_net = NeuralNet(nS, nA, torch.nn.Softmax())\n",
    "else:\n",
    "    nS = env.observation_space.shape[0]\n",
    "    nA = env.action_space.shape[0]\n",
    "    policy_net = ContinuousActor(nS, nA)\n",
    "\n",
    "# load the policy network\n",
    "policy_net.load_state_dict(torch.load(f\"policy_net_{env_name}.pt\"))\n",
    "# policy_net.eval()\n",
    "\n",
    "print(f\"test_actor: {policy_net.forward(torch.tensor([1, 2, 3], dtype=torch.float32))}\")\n",
    "episodes = 2\n",
    "state = env.reset()[0]\n",
    "for i in range(episodes):\n",
    "    for i in range (200):\n",
    "        action, _ = policy_net.forward(torch.tensor(state, dtype=torch.float32))\n",
    "        # clip action to the action space\n",
    "        action = torch.clamp(action, min=-2, max=2)\n",
    "        \n",
    "        # take a selected action\n",
    "        state, reward, done, truncated, _ = env.step([action])\n",
    "        if done or truncated:\n",
    "            break\n",
    "        state = torch.from_numpy(state.flatten()).float()\n",
    "    \n",
    "    \n",
    "# for i in range(episodes):\n",
    "#     try:\n",
    "#         reward = evaluate_policy(env, policy_net)\n",
    "#     except Exception as e:\n",
    "#         # print error and traceback\n",
    "#         print(e)\n",
    "        \n",
    "#         env.close()\n",
    "\n",
    "#     print(f\"Episode {i}: {reward}\")\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = 'Pendulum-v1' # environment name\n",
    "env = gym.make(env_name, render_mode='human')\n",
    "action = 2\n",
    "state = env.reset()[0]\n",
    "for i in range(200):\n",
    "    state, reward, done, truncated, _ = env.step([action])\n",
    "    if done or truncated:\n",
    "        break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1252830459db436a85b9800859f42f71": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bb26d51d2d4e4bfcbb78ebc6d3d05f6b",
       "IPY_MODEL_248b8eb6d6d246e5b108afa59b6c53af"
      ],
      "layout": "IPY_MODEL_85ea1f2de43740659776d173f81b9e11"
     }
    },
    "171dadde77184657add3f9136b23b00e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "248b8eb6d6d246e5b108afa59b6c53af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f3d9e9d1989d40438c07c1b652d747dd",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7a0c39bd339746f794a67281a2442ad2",
      "value": 1
     }
    },
    "456be98214854aa2b6c3ac281a078ad4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "78c135b964044bcf841f6bb944e01b06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9392daa2b25d4a27b681b7c836bdbf4a",
      "placeholder": "​",
      "style": "IPY_MODEL_456be98214854aa2b6c3ac281a078ad4",
      "value": "0.066 MB of 0.066 MB uploaded (0.000 MB deduped)\r"
     }
    },
    "7a0c39bd339746f794a67281a2442ad2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7c4c2ae0c4454b07b3a5d63dca8d795c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85ea1f2de43740659776d173f81b9e11": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8627cad6d7864563a89132995c034182": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9c4a0434c7a7413289ff097106d7318c",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f3a393a56c20445d848adc997aa8018e",
      "value": 1
     }
    },
    "9392daa2b25d4a27b681b7c836bdbf4a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c4a0434c7a7413289ff097106d7318c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aaecdcf1288446f9b7cd84f4f3044de0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_78c135b964044bcf841f6bb944e01b06",
       "IPY_MODEL_8627cad6d7864563a89132995c034182"
      ],
      "layout": "IPY_MODEL_171dadde77184657add3f9136b23b00e"
     }
    },
    "bb26d51d2d4e4bfcbb78ebc6d3d05f6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c4c2ae0c4454b07b3a5d63dca8d795c",
      "placeholder": "​",
      "style": "IPY_MODEL_c657703d2bce404d87e4dd41a28222d4",
      "value": "0.019 MB of 0.019 MB uploaded (0.000 MB deduped)\r"
     }
    },
    "c657703d2bce404d87e4dd41a28222d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f3a393a56c20445d848adc997aa8018e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f3d9e9d1989d40438c07c1b652d747dd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
