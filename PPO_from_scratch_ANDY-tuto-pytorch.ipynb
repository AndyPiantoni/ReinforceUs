{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from IPython import display\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# check and use GPU if available if not use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from torch.distributions import MultivariateNormal, Normal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContinuousActor(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_dim: int, \n",
    "        out_dim: int, \n",
    "    ):\n",
    "        \"\"\"Initialize.\"\"\"\n",
    "        super(ContinuousActor, self).__init__()\n",
    "\n",
    "        self.hidden1 = nn.Linear(in_dim, 32)\n",
    "        self.hidden2 = nn.Linear(32, 32)\n",
    "        self.hidden3 = nn.Linear(32, 32)\n",
    "        self.mu_layer = nn.Linear(32, out_dim)\n",
    "        self.log_std_layer = nn.Linear(32, out_dim)\n",
    "\n",
    "    def forward(self, state: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward method implementation.\"\"\"\n",
    "        x = F.relu(self.hidden1(state))\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = F.relu(self.hidden3(x))\n",
    "        \n",
    "        mu = torch.tanh(self.mu_layer(x))\n",
    "        log_std = torch.tanh(self.log_std_layer(x))\n",
    "\n",
    "        std = torch.exp(log_std)\n",
    "        dist = Normal(mu, std)\n",
    "        action = dist.sample()\n",
    "\n",
    "        return action, dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_actor = ContinuousActor(3, 1)\n",
    "action, dist = test_actor.forward(torch.tensor([1, 2, 3], dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_reward_mountaincar(state, reward):\n",
    "    if reward > 0:\n",
    "        return 500\n",
    "    pos = state[0]+0.5\n",
    "    vel = state[1]\n",
    "    return (abs(pos) + abs(vel)*14.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE from another notebook\n",
    "class NeuralNet(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size, activation, layers=[32,32,16]):\n",
    "        super().__init__()\n",
    "\n",
    "        # Define layers with ReLU activation\n",
    "        self.linear1 = torch.nn.Linear(input_size, layers[0])\n",
    "        self.activation1 = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(layers[0], layers[1])\n",
    "        self.activation2 = torch.nn.ReLU()\n",
    "        self.linear3 = torch.nn.Linear(layers[1], layers[2])\n",
    "        self.activation3 = torch.nn.ReLU()\n",
    "\n",
    "        self.output_layer = torch.nn.Linear(layers[2], output_size)\n",
    "        self.output_activation = activation\n",
    "\n",
    "        # Initialization using Xavier normal (a popular technique for initializing weights in NNs)\n",
    "        torch.nn.init.xavier_normal_(self.linear1.weight)\n",
    "        torch.nn.init.xavier_normal_(self.linear2.weight)\n",
    "        torch.nn.init.xavier_normal_(self.linear3.weight)\n",
    "        torch.nn.init.xavier_normal_(self.output_layer.weight)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Forward pass through the layers\n",
    "        x = self.activation1(self.linear1(inputs))\n",
    "        x = self.activation2(self.linear2(x))\n",
    "        x = self.activation3(self.linear3(x))\n",
    "        x = self.output_activation(self.output_layer(x))\n",
    "        return x\n",
    "\n",
    "def normalize_reward(env, reward):\n",
    "    \"\"\"\n",
    "    Normalize the reward between -1 and 1 for pendulum environment\n",
    "    \"\"\"\n",
    "    return (reward + 8.1) / 8.1\n",
    "\n",
    "def generate_single_episode(env, policy_net, eval=False, nS=None, nA=None, discretized_continuous_action_space=False, actions_transform=None):\n",
    "    \"\"\"\n",
    "    Generates an episode by executing the current policy in the given env\n",
    "    \"\"\"\n",
    "    states = []\n",
    "    actions = []\n",
    "    rewards = []\n",
    "    log_probs = []\n",
    "    max_t = 1000 # max horizon within one episode\n",
    "    state, _ = env.reset()\n",
    "\n",
    "    if isinstance(env.action_space, gym.spaces.Box):\n",
    "        max_possible_action = float(env.action_space.high[0]) # Only works with a action space dim of 1\n",
    "        min_possible_action = float(env.action_space.low[0]) # Only works with a action space dim of 1\n",
    "\n",
    "    for t in range(max_t):\n",
    "        #print(t)\n",
    "        if isinstance(env.action_space, gym.spaces.Discrete) or discretized_continuous_action_space:\n",
    "            state = torch.from_numpy(state).float().unsqueeze(0)\n",
    "        else:\n",
    "            state = torch.from_numpy(state.flatten()).float()\n",
    "            \n",
    "\n",
    "        # if action space is discrete or continuous\n",
    "        if isinstance(env.action_space, gym.spaces.Discrete) or discretized_continuous_action_space:\n",
    "            probs = policy_net.forward(Variable(state)) # get each action choice probability with the current policy network\n",
    "            action = np.random.choice(nA, p=np.squeeze(probs.detach().numpy())) # probablistic\n",
    "        else:\n",
    "            action, dist = policy_net.forward(state) # continuous\n",
    "            # clip action to the action space\n",
    "            action = torch.clamp(action, min=min_possible_action, max=max_possible_action)\n",
    "            action = action.detach().numpy()\n",
    "            probs = dist\n",
    "\n",
    "\n",
    "        # compute the log_prob to use this in parameter update\n",
    "        log_prob = None\n",
    "        if isinstance(env.action_space, gym.spaces.Discrete) or discretized_continuous_action_space:\n",
    "            log_prob = torch.log(probs.squeeze(0)[action])\n",
    "        else:\n",
    "            log_prob = dist.log_prob(torch.tensor(action))\n",
    "            # print(f\"log_prob: {log_prob}\")\n",
    "            \n",
    "        #print(log_prob)\n",
    "        \n",
    "        # append values\n",
    "        states.append(state)\n",
    "        actions.append(action)\n",
    "        log_probs.append(log_prob)\n",
    "        \n",
    "        # take a selected action\n",
    "        if discretized_continuous_action_space:\n",
    "            assert actions_transform is not None, \"actions_transform must be provided for discretized_continuous_action_space\" \n",
    "            state, reward, terminated, truncated, _ = env.step([actions_transform[action]])\n",
    "        else:\n",
    "            state, reward, terminated, truncated, _ = env.step(action)\n",
    "\n",
    "        if terminated and env.spec.id == 'MountainCar-v0':\n",
    "            print(f\"Envrionement solved in {t} steps\")\n",
    "        if not eval:\n",
    "            # normalize the reward between -1 and 1\n",
    "            # reward = (reward + 8.1) / 8.1\n",
    "            if isinstance(env.action_space, gym.spaces.Discrete):\n",
    "                # env name == 'MountainCar-v0'\n",
    "                if env.spec.id == 'MountainCar-v0':\n",
    "                    # reward = new_reward_mountaincar(state, reward)\n",
    "                    pass # do nothing\n",
    "            elif discretized_continuous_action_space:\n",
    "                reward = normalize_reward(env, reward)\n",
    "            else:\n",
    "                reward = normalize_reward(env, reward)\n",
    "        \n",
    "        rewards.append(reward)\n",
    "\n",
    "        if terminated | truncated:\n",
    "            break\n",
    "            \n",
    "    return states, actions, rewards, log_probs\n",
    "\n",
    "\n",
    "def evaluate_policy(env, policy_net, nS=None, nA=None, discretized_continuous_action_space=False, actions_transform=None):\n",
    "    \"\"\"\n",
    "    Compute accumulative trajectory reward\n",
    "    \"\"\"\n",
    "    states, actions, rewards, log_probs = generate_single_episode(env, policy_net, eval=True, nS=nS, nA=nA, discretized_continuous_action_space=discretized_continuous_action_space, actions_transform=actions_transform)\n",
    "    return np.sum(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_PPO(env, policy_net, policy_optimizer, value_net, value_optimizer, num_epochs, clip_val=0.2, gamma=0.99, entropy_coef=0.005, lamda=0.95, vf_coef=1, \n",
    "nS=0, nA=0, discretized_continuous_action_space=False, actions_transform=0):\n",
    "    \"\"\"\n",
    "    Trains the policy network using PPO\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate an episode with the current policy network\n",
    "    states, actions, rewards, log_probs = generate_single_episode(env, policy_net, nS=nS, nA=nA, \n",
    "                                                                discretized_continuous_action_space=discretized_continuous_action_space, \n",
    "                                                                actions_transform=actions_transform)\n",
    "    T = len(states)\n",
    "    \n",
    "    # Create tensors depending on if it is discrete or continuous action space\n",
    "    if isinstance(env.action_space, gym.spaces.Discrete) or discretized_continuous_action_space:\n",
    "        actions = torch.LongTensor(actions).to(device).view(-1,1)\n",
    "    else:\n",
    "        actions = torch.FloatTensor(actions).to(device).view(-1,1)\n",
    "\n",
    "\n",
    "    states = np.vstack(states).astype(float)\n",
    "    states = torch.FloatTensor(states).to(device)\n",
    "    rewards = torch.FloatTensor(rewards).to(device).view(-1,1)\n",
    "    log_probs = torch.FloatTensor(log_probs).to(device).view(-1,1)\n",
    "\n",
    "    # Compute the generalized advantage estimate\n",
    "    Gs = []\n",
    "    G = 0\n",
    "    for t in range(T-1,-1,-1):\n",
    "        delta = (rewards[t] + gamma*value_net(states[t]) - value_net(states[t-1]))\n",
    "        G = delta + gamma * G * lamda\n",
    "        Gs.insert(0,G)\n",
    "    Gs = torch.tensor(Gs).view(-1,1)\n",
    "    # for t in range(T-1,-1,-1): # iterate in backward order to make the computation easier\n",
    "    #     G = rewards[t] + gamma*G\n",
    "    #     Gs.insert(0,G)\n",
    "    # Gs = torch.tensor(Gs).view(-1,1)\n",
    "    \n",
    "    # Compute the advantage\n",
    "    state_vals = value_net(states).to(device)\n",
    "    with torch.no_grad():\n",
    "        A_k = Gs - state_vals\n",
    "        \n",
    "    for _ in range(num_epochs):\n",
    "        # Compute the value of the current states\n",
    "        V = value_net(states).to(device)\n",
    "\n",
    "\n",
    "        # Calculate probability of each action under the updated policy\n",
    "        # compute the log_prob to use it in parameter update\n",
    "        if isinstance(env.action_space, gym.spaces.Discrete) or discretized_continuous_action_space:\n",
    "            probs = policy_net.forward(states).to(device)\n",
    "            curr_log_probs = torch.log(torch.gather(probs, 1, actions))\n",
    "            # print(f\"probs, discrete: {probs}\")\n",
    "        else:\n",
    "            _, probs = policy_net.forward(states)\n",
    "            curr_log_probs = probs.log_prob(actions)\n",
    "            # print(f\"probs, continuous: {probs}\")\n",
    "\n",
    "        # Calculate ratios r(theta)\n",
    "        ratios = torch.exp(curr_log_probs - log_probs)\n",
    "        \n",
    "        # Calculate two surrogate loss terms in cliped loss\n",
    "        surr1 = ratios * A_k\n",
    "        surr2 = torch.clamp(ratios, 1-clip_val, 1+clip_val) * A_k\n",
    "        \n",
    "        # entropy  \n",
    "        if isinstance(env.action_space, gym.spaces.Discrete) or discretized_continuous_action_space:\n",
    "            # get entropy from discrete probs\n",
    "            entropy = -(probs * torch.log(probs)).sum(dim=1).mean()\n",
    "            # get value loss\n",
    "            value_loss = nn.MSELoss()(V, Gs)\n",
    "            actor_loss = (-torch.min(surr1, surr2).mean() - entropy_coef * entropy + vf_coef * value_loss)\n",
    "            # Calculate clipped loss value\n",
    "            # actor_loss = (-torch.min(surr1, surr2)).mean() # Need negative sign to run Gradient Ascent\n",
    "        else:\n",
    "            entropy = probs.entropy().mean()\n",
    "            actor_loss = (-torch.min(surr1, surr2).mean() - entropy_coef * entropy)\n",
    "\n",
    "            \n",
    "        \n",
    "        # Update policy network\n",
    "        policy_optimizer.zero_grad()\n",
    "        actor_loss.backward(retain_graph=True)\n",
    "        policy_optimizer.step()\n",
    "        \n",
    "        # Update value net\n",
    "        critic_loss = nn.MSELoss()(V, Gs)\n",
    "        value_optimizer.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        value_optimizer.step()\n",
    "        \n",
    "    return policy_net, value_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0\n",
      "The avg. test reward for episode 0 is -1197.9415774001097 with std of 265.92279934352354.\n",
      "Episode: 50\n",
      "The avg. test reward for episode 50 is -1286.6705827366463 with std of 279.55200570409494.\n",
      "Episode: 100\n",
      "The avg. test reward for episode 100 is -1261.831965789897 with std of 216.84114175548726.\n",
      "Episode: 150\n",
      "The avg. test reward for episode 150 is -1103.2171661698878 with std of 200.63814411681724.\n",
      "Episode: 200\n",
      "The avg. test reward for episode 200 is -1119.4084888401935 with std of 169.8392090946387.\n",
      "Episode: 250\n",
      "The avg. test reward for episode 250 is -1019.23464724997 with std of 169.00403186384963.\n",
      "Episode: 300\n",
      "The avg. test reward for episode 300 is -1068.5802344658373 with std of 172.03045991788153.\n",
      "Episode: 350\n",
      "The avg. test reward for episode 350 is -1097.405623859258 with std of 214.3936100630669.\n",
      "Episode: 400\n",
      "The avg. test reward for episode 400 is -1100.9883279051205 with std of 205.22721533694556.\n",
      "Episode: 450\n",
      "The avg. test reward for episode 450 is -1025.9270320714115 with std of 132.28603397833712.\n",
      "Episode: 500\n",
      "The avg. test reward for episode 500 is -1099.6155770075534 with std of 152.2896352739473.\n",
      "Episode: 550\n",
      "The avg. test reward for episode 550 is -1059.291342122547 with std of 147.01794332885044.\n",
      "Episode: 600\n",
      "The avg. test reward for episode 600 is -994.9248435591693 with std of 132.6219853519574.\n",
      "Episode: 650\n",
      "The avg. test reward for episode 650 is -1062.2835505822231 with std of 147.0806200409555.\n",
      "Episode: 700\n",
      "The avg. test reward for episode 700 is -989.5880863990566 with std of 162.2608784582083.\n",
      "Episode: 750\n",
      "The avg. test reward for episode 750 is -1007.6616216992568 with std of 156.86900577629865.\n",
      "Episode: 800\n",
      "The avg. test reward for episode 800 is -894.7599812642569 with std of 108.2093966128228.\n",
      "Episode: 850\n",
      "The avg. test reward for episode 850 is -911.6321098012025 with std of 140.82907413111917.\n",
      "Episode: 900\n",
      "The avg. test reward for episode 900 is -836.5151416705845 with std of 104.92264964092554.\n",
      "Episode: 950\n",
      "The avg. test reward for episode 950 is -850.5612027614877 with std of 127.43272922830167.\n",
      "Episode: 1000\n",
      "The avg. test reward for episode 1000 is -849.9462889086099 with std of 115.2220736475606.\n",
      "Episode: 1050\n",
      "The avg. test reward for episode 1050 is -763.8975339980568 with std of 94.9260349867621.\n",
      "Episode: 1100\n",
      "The avg. test reward for episode 1100 is -730.6662151303566 with std of 135.5328104713083.\n",
      "Episode: 1150\n",
      "The avg. test reward for episode 1150 is -740.2340070701839 with std of 123.09381755514455.\n",
      "Episode: 1200\n",
      "The avg. test reward for episode 1200 is -638.9484141316655 with std of 130.31319180334074.\n",
      "Episode: 1250\n",
      "The avg. test reward for episode 1250 is -390.27012925915676 with std of 221.33547226340482.\n",
      "Episode: 1300\n",
      "The avg. test reward for episode 1300 is -301.40195958211564 with std of 138.49923527156594.\n",
      "Episode: 1350\n",
      "The avg. test reward for episode 1350 is -335.7476300722926 with std of 152.45646936757487.\n",
      "Episode: 1400\n",
      "The avg. test reward for episode 1400 is -263.89902245796554 with std of 139.32524727411078.\n",
      "Episode: 1450\n",
      "The avg. test reward for episode 1450 is -293.36239118918684 with std of 232.0264860081622.\n",
      "Episode: 1500\n",
      "The avg. test reward for episode 1500 is -325.1007874343294 with std of 256.846634813885.\n",
      "Episode: 1550\n",
      "The avg. test reward for episode 1550 is -293.81441360784004 with std of 202.46987945968988.\n",
      "Episode: 1600\n",
      "The avg. test reward for episode 1600 is -235.05984415094537 with std of 147.53958576510712.\n",
      "Episode: 1650\n",
      "The avg. test reward for episode 1650 is -218.01005892307649 with std of 141.3614822723795.\n",
      "Episode: 1700\n",
      "The avg. test reward for episode 1700 is -390.69365270380405 with std of 150.02908181964628.\n",
      "Episode: 1750\n",
      "The avg. test reward for episode 1750 is -265.20416477536 with std of 118.16595399299614.\n",
      "Episode: 1800\n",
      "The avg. test reward for episode 1800 is -240.05955035375314 with std of 132.0532220911683.\n",
      "Episode: 1850\n",
      "The avg. test reward for episode 1850 is -192.11852558977708 with std of 127.7412925353331.\n",
      "Episode: 1900\n",
      "The avg. test reward for episode 1900 is -322.4291754941412 with std of 134.65035447099308.\n",
      "Episode: 1950\n",
      "The avg. test reward for episode 1950 is -262.3214241519991 with std of 138.6176193227331.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [13:04<00:00, 784.31s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'PPO Learning Curve')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "# Define parameter values\n",
    "#env_name = 'CartPole-v1' # environment name\n",
    "env_name = 'Pendulum-v1' # environment name\n",
    "# env_name = \"MountainCarContinuous-v0\"\n",
    "\n",
    "# env_name = 'LunarLander-v2' # environment name\n",
    "# env_name = 'MountainCar-v0' # environment name\n",
    "# env_name = 'Acrobot-v1' # environment name\n",
    "\n",
    "\n",
    "num_train_ite = 2000 # number of training iterations\n",
    "num_seeds = 1 # fit model with 3 different seeds and plot average performance of 3 seeds\n",
    "num_epochs = 10 # how many times we iterate the entire training dataset passing through the training\n",
    "eval_freq = 50 # run evaluation of policy at each eval_freq trials\n",
    "eval_epi_index = num_train_ite//eval_freq # use to create x label for plot\n",
    "returns = np.zeros((num_seeds, eval_epi_index))\n",
    "gamma = 0.999 # discount factor\n",
    "lamda = 0.95 # GAE hyperparameter\n",
    "clip_val = 0.2 # hyperparameter epsilon in clip objective\n",
    "entropy_coef = 0.005 # hyperparameter entropy coefficient \n",
    "vf_coef = 0 # hyperparameter value function coefficient\n",
    "policy_lr = 1e-4 # policy network's learning rate \n",
    "baseline_lr = 5e-4 # value network's learning rate\n",
    "\n",
    "# Create the environment.\n",
    "env = gym.make(env_name)\n",
    "\n",
    "# For discretization of the action space\n",
    "discretized_continuous_action_space = True\n",
    "    \n",
    "actions_transform = None\n",
    "if discretized_continuous_action_space:\n",
    "    action_range = (env.action_space.low[0], env.action_space.high[0])\n",
    "    n_actions = 21\n",
    "    actions_transform = np.linspace(action_range[0], action_range[1], n_actions)\n",
    "\n",
    "\n",
    "\n",
    "#detect if the environment is discrete or continuous\n",
    "if isinstance(env.action_space, gym.spaces.Discrete):\n",
    "    nA = env.action_space.n\n",
    "else:\n",
    "    if discretized_continuous_action_space:\n",
    "        nA = n_actions\n",
    "    else:\n",
    "        nA = env.action_space.shape[0]\n",
    "\n",
    "# detect if the environment state is discrete or continuous\n",
    "if isinstance(env.observation_space, gym.spaces.Discrete):\n",
    "    nS = env.observation_space.n\n",
    "else:\n",
    "    nS = env.observation_space.shape[0]\n",
    "\n",
    "epoch_times = []\n",
    "final_policy_nets = []\n",
    "for i in tqdm.tqdm(range(num_seeds)):\n",
    "    reward_means = []\n",
    "    # Set random seed\n",
    "    seed = np.random.randint(0, 1000)\n",
    "    torch.manual_seed(seed)\n",
    "    # Define policy and value networks\n",
    "    if isinstance(env.action_space, gym.spaces.Discrete) or discretized_continuous_action_space:\n",
    "        policy_net = NeuralNet(nS, nA, torch.nn.Softmax()) # Normally this one works with CartPole-v0\n",
    "    else:\n",
    "        #policy_net = NeuralNet(nS, nA, torch.nn.Identity())\n",
    "        policy_net = ContinuousActor(nS, nA)\n",
    "    policy_net_optimizer = optim.Adam(policy_net.parameters(), lr=policy_lr)\n",
    "    value_net = NeuralNet(nS, 1, torch.nn.ReLU())\n",
    "    value_net_optimizer = optim.Adam(value_net.parameters(), lr=baseline_lr)\n",
    "\n",
    "    epoch_start_time = 0 #********************************************************************************************************************\n",
    "    epoch_end_time = 0 #**********************************************************************************************************************\n",
    "\n",
    "    for m in range(num_train_ite):\n",
    "        epoch_start_time = time.time()\n",
    "        # Train networks with PPO\n",
    "        policy_net, value_net = train_PPO(env, policy_net, policy_net_optimizer, \n",
    "                                          value_net, value_net_optimizer, num_epochs, \n",
    "                                          clip_val=clip_val, gamma=gamma,\n",
    "                                          entropy_coef=entropy_coef, lamda=lamda,\n",
    "                                          vf_coef=vf_coef,\n",
    "                                          nS=nS, nA=nA, \n",
    "                                          discretized_continuous_action_space=discretized_continuous_action_space, \n",
    "                                          actions_transform=actions_transform)\n",
    "        epoch_end_time = time.time()\n",
    "        epoch_times.append(epoch_end_time - epoch_start_time)\n",
    "        if m % eval_freq == 0:\n",
    "            print(\"Episode: {}\".format(m))\n",
    "            G = np.zeros(20)\n",
    "            for k in range(20):\n",
    "                g = evaluate_policy(env, policy_net, nS=nS, nA=nA, \n",
    "                                    discretized_continuous_action_space=discretized_continuous_action_space, \n",
    "                                    actions_transform=actions_transform)\n",
    "                G[k] = g\n",
    "\n",
    "            reward_mean = G.mean()\n",
    "            reward_sd = G.std()\n",
    "            print(\"The avg. test reward for episode {0} is {1} with std of {2}.\".format(m, reward_mean, reward_sd))\n",
    "            reward_means.append(reward_mean)\n",
    "\n",
    "    returns[i] = np.array(reward_means)\n",
    "    final_policy_nets.append(policy_net)\n",
    "\n",
    "# save the policy network\n",
    "torch.save(policy_net.state_dict(), f\"PPO_policy_net_{env_name}.pt\")\n",
    "\n",
    "\n",
    "# Plot the performance over iterations\n",
    "x = np.arange(eval_epi_index)*eval_freq\n",
    "avg_returns = np.mean(returns, axis=0)\n",
    "max_returns = np.max(returns, axis=0)\n",
    "min_returns = np.min(returns, axis=0)\n",
    "\n",
    "plt.fill_between(x, min_returns, max_returns, alpha=0.1)\n",
    "plt.plot(x, avg_returns, '-o', markersize=1)\n",
    "\n",
    "plt.xlabel('Episode', fontsize = 15)\n",
    "plt.ylabel('Return', fontsize = 15)\n",
    "\n",
    "plt.title(\"PPO Learning Curve\", fontsize = 24)\n",
    "\n",
    "# # Save a plot about the time taken for each epoch\n",
    "# x = np.arange(len(epoch_times))\n",
    "# plt.plot(x, epoch_times, '-o', markersize=1)\n",
    "# # add average epoch time\n",
    "# avg_epoch_time = np.mean(epoch_times)\n",
    "# print(f\"Average epoch time: {avg_epoch_time}\")\n",
    "# plt.axhline(y=avg_epoch_time, color='r', linestyle='-', label=f'Average time: {avg_epoch_time:.2f}')\n",
    "# plt.legend()\n",
    "# plt.xlabel('Epoch', fontsize = 15)\n",
    "# plt.ylabel('Time (s)', fontsize = 15)\n",
    "# plt.title(\"Time taken for each epoch\", fontsize = 24)\n",
    "\n",
    "# plt.savefig(f\"PPO_{env_name}_time_per_epoch.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lisas\\miniconda3\\envs\\Reinforce\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0: 499.0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Variable data has to be a tensor, but got numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 35\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(env\u001b[38;5;241m.\u001b[39maction_space, gym\u001b[38;5;241m.\u001b[39mspaces\u001b[38;5;241m.\u001b[39mDiscrete):\n\u001b[1;32m---> 35\u001b[0m         probs \u001b[38;5;241m=\u001b[39m policy_net\u001b[38;5;241m.\u001b[39mforward(\u001b[43mVariable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;66;03m# get each action choice probability with the current policy network\u001b[39;00m\n\u001b[0;32m     36\u001b[0m         action \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(env\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mn, p\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39msqueeze(probs\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy())) \u001b[38;5;66;03m# probablistic\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mTypeError\u001b[0m: Variable data has to be a tensor, but got numpy.ndarray"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import time\n",
    "#create an environment to test and visualize the policy\n",
    "env_name = 'CartPole-v1' # environment name\n",
    "# env_name = 'Pendulum-v1' # environment name\n",
    "# env_name = 'MountainCar-v0' # environment name\n",
    "# env_name = 'Acrobot-v1' # environment name\n",
    "# env_name = \"MountainCarContinuous-v0\"\n",
    "env = gym.make(env_name, render_mode='human')\n",
    "\n",
    "if isinstance(env.action_space, gym.spaces.Discrete):\n",
    "    nS = env.observation_space.shape[0]\n",
    "    nA = env.action_space.n\n",
    "    policy_net = NeuralNet(nS, nA, torch.nn.Softmax())\n",
    "else:\n",
    "    nS = env.observation_space.shape[0]\n",
    "    nA = env.action_space.shape[0]\n",
    "    policy_net = ContinuousActor(nS, nA)\n",
    "\n",
    "# load the policy network\n",
    "policy_net.load_state_dict(torch.load(f\"PPO_policy_net_{env_name}.pt\"))\n",
    "# policy_net.eval()\n",
    "\n",
    "episodes = 5\n",
    "state, _ = env.reset()\n",
    "if isinstance(env.action_space, gym.spaces.Discrete):\n",
    "    state = torch.from_numpy(state).float().unsqueeze(0)\n",
    "else:\n",
    "    state = env.reset()[0]\n",
    "rewards = []\n",
    "avg_rewards = []\n",
    "for i in range(episodes):\n",
    "    rewards = []\n",
    "    while True:\n",
    "        if isinstance(env.action_space, gym.spaces.Discrete):\n",
    "            probs = policy_net.forward(Variable(state)) # get each action choice probability with the current policy network\n",
    "            action = np.random.choice(env.action_space.n, p=np.squeeze(probs.detach().numpy())) # probablistic\n",
    "        else:\n",
    "            action, _ = policy_net.forward(torch.tensor(state, dtype=torch.float32))\n",
    "        if isinstance(env.action_space, gym.spaces.Discrete):\n",
    "            pass\n",
    "        else:\n",
    "            # clip action to the action space\n",
    "            action = torch.clamp(action, min=-2, max=2)\n",
    "            # take a selected action\n",
    "            action = action.detach().numpy()\n",
    "        \n",
    "        \n",
    "        state, reward, done, truncated, _ = env.step(action)\n",
    "        if done or truncated:\n",
    "            break\n",
    "        state = torch.from_numpy(state.flatten()).float()\n",
    "        rewards.append(reward)\n",
    "    avg_rewards.append(np.sum(rewards))\n",
    "    print(f\"Episode {i}: {np.sum(rewards)}\")\n",
    "    env.reset()\n",
    "print(f\"Average reward: {np.mean(avg_rewards)} over {episodes} episodes\")\n",
    "env.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lisas\\miniconda3\\envs\\Reinforce\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0: 500.0\n",
      "Episode 1: 500.0\n",
      "Episode 2: 500.0\n",
      "Episode 3: 500.0\n",
      "Episode 4: 500.0\n",
      "Average reward: 500.0 over 5 episodes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "#create an environment to test and visualize the policy\n",
    "env_name = 'CartPole-v1' # environment name\n",
    "# env_name = 'Pendulum-v1' # environment name\n",
    "# env_name = 'MountainCar-v0' # environment name\n",
    "# env_name = 'Acrobot-v1' # environment name\n",
    "# env_name = \"MountainCarContinuous-v0\"\n",
    "env = gym.make(env_name, render_mode='human')\n",
    "\n",
    "if isinstance(env.action_space, gym.spaces.Discrete):\n",
    "    nS = env.observation_space.shape[0]\n",
    "    nA = env.action_space.n\n",
    "    policy_net = NeuralNet(nS, nA, torch.nn.Softmax())\n",
    "else:\n",
    "    nS = env.observation_space.shape[0]\n",
    "    nA = env.action_space.shape[0]\n",
    "    policy_net = ContinuousActor(nS, nA)\n",
    "\n",
    "# load the policy network\n",
    "policy_net.load_state_dict(torch.load(f\"PPO_policy_net_{env_name}.pt\"))\n",
    "# policy_net.eval()\n",
    "\n",
    "episodes = 5\n",
    "state, _ = env.reset()\n",
    "if isinstance(env.action_space, gym.spaces.Discrete):\n",
    "    state = torch.from_numpy(state).float().unsqueeze(0)\n",
    "else:\n",
    "    state = env.reset()[0]\n",
    "rewards = []\n",
    "for i in range(episodes):\n",
    "    rewards.append(evaluate_policy(env, policy_net))\n",
    "    print(f\"Episode {i}: {rewards[-1]}\")\n",
    "    env.reset()\n",
    "print(f\"Average reward: {np.mean(rewards)} over {episodes} episodes\")\n",
    "env.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1252830459db436a85b9800859f42f71": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bb26d51d2d4e4bfcbb78ebc6d3d05f6b",
       "IPY_MODEL_248b8eb6d6d246e5b108afa59b6c53af"
      ],
      "layout": "IPY_MODEL_85ea1f2de43740659776d173f81b9e11"
     }
    },
    "171dadde77184657add3f9136b23b00e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "248b8eb6d6d246e5b108afa59b6c53af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f3d9e9d1989d40438c07c1b652d747dd",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7a0c39bd339746f794a67281a2442ad2",
      "value": 1
     }
    },
    "456be98214854aa2b6c3ac281a078ad4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "78c135b964044bcf841f6bb944e01b06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9392daa2b25d4a27b681b7c836bdbf4a",
      "placeholder": "​",
      "style": "IPY_MODEL_456be98214854aa2b6c3ac281a078ad4",
      "value": "0.066 MB of 0.066 MB uploaded (0.000 MB deduped)\r"
     }
    },
    "7a0c39bd339746f794a67281a2442ad2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7c4c2ae0c4454b07b3a5d63dca8d795c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85ea1f2de43740659776d173f81b9e11": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8627cad6d7864563a89132995c034182": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9c4a0434c7a7413289ff097106d7318c",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f3a393a56c20445d848adc997aa8018e",
      "value": 1
     }
    },
    "9392daa2b25d4a27b681b7c836bdbf4a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c4a0434c7a7413289ff097106d7318c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aaecdcf1288446f9b7cd84f4f3044de0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_78c135b964044bcf841f6bb944e01b06",
       "IPY_MODEL_8627cad6d7864563a89132995c034182"
      ],
      "layout": "IPY_MODEL_171dadde77184657add3f9136b23b00e"
     }
    },
    "bb26d51d2d4e4bfcbb78ebc6d3d05f6b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c4c2ae0c4454b07b3a5d63dca8d795c",
      "placeholder": "​",
      "style": "IPY_MODEL_c657703d2bce404d87e4dd41a28222d4",
      "value": "0.019 MB of 0.019 MB uploaded (0.000 MB deduped)\r"
     }
    },
    "c657703d2bce404d87e4dd41a28222d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f3a393a56c20445d848adc997aa8018e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f3d9e9d1989d40438c07c1b652d747dd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
