{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, an implementation for the DQN algorithm takes place (hopefully)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "install notes: \n",
    "\n",
    "pip install pytorch\n",
    "\n",
    "pip install matplotlib\n",
    "\n",
    "pip install gymnasium[classic_control]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import gymnasium as gym\n",
    "import math\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# if GPU is to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Algorithm we want to implement is Deep-Q learning with Experience Replay\n",
    "The pseudocode outline of the Algorithm can be seen below:\n",
    "\n",
    "\n",
    "&ensp;Initialize replay memory D to capacity N<br>\n",
    "&ensp;Initialize action-value function Q with random weights<br>\n",
    "&ensp;**for** episode = 1, M **do** <br>\n",
    "&ensp;&ensp;&ensp; Initialise sequence $s1 = {x1}$ and preprocessed sequenced $\\phi_1 = \\phi(s1)$<br>\n",
    "&ensp;&ensp;&ensp; **for** t = 1, T **do** <br>\n",
    "&ensp;&ensp;&ensp;&ensp;&ensp; With probability $\\epsilon$ select a random action $a_t$<br>\n",
    "&ensp;&ensp;&ensp;&ensp;&ensp; otherwise select $a_t = max_a Q^*(\\phi(s_t),a;\\theta)$<br>\n",
    "&ensp;&ensp;&ensp;&ensp;&ensp; Execute action $a_t$ in emulator and observe reward $r_t$ and image $x_{t+1}$<br>\n",
    "&ensp;&ensp;&ensp;&ensp;&ensp; Set $s_{t+1} = s_t ,a_t ,x_{t+1}$ and preprocess $\\phi_{t+1} = \\phi(s_{t+1})$<br>\n",
    "&ensp;&ensp;&ensp;&ensp;&ensp; Store transition $(\\phi_t ,a_t,r_t,\\phi_{t+1})$ in D<br>\n",
    "&ensp;&ensp;&ensp;&ensp;&ensp; Sample random minibatch of transitions $(\\phi_j , a_j, r_j, \\phi_{j+1})$ from D<br>\n",
    "\n",
    "&ensp;&ensp;&ensp;&ensp;&ensp;$\n",
    "\\text{Set} \\ y = \\begin{cases}\n",
    "r_j, & \\text{for terminal} \\ \\phi_{j+1} \\\\\n",
    "r_j+\\gamma \\ max_{a^{'}}Q(\\phi_{j+1}, a';\\theta), & \\text{for non-terminal } \\ \\phi_{j+1}\n",
    "\\end{cases}\n",
    "$\n",
    "\n",
    "&ensp;&ensp;&ensp;&ensp;&ensp;Perform a gradient descent step on $(y_j − Q(\\phi_j, a_j; \\theta))²$<br>\n",
    "&ensp;&ensp;&ensp;**end for**<br>\n",
    "&ensp;**end for**\n",
    "\n",
    "The gradient descent step is given by:<br>\n",
    "$\\nabla_{\\theta_i}L_i(\\theta_i) = \\mathbb{E}_{s, a \\sim p(\\cdot);s'\\sim \\epsilon} \\big[\\big(r+\\gamma \\max_{a'} Q(s', a';\\theta_{i-1})-Q(s,a;\\theta_i)\\big)\\nabla_{\\theta_i}(s,a;\\theta_i) \\big]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Notes: <br>\n",
    "3 processes:<br>\n",
    "- Process 1: Data Aquisition to fill buffer (latest Q function with some exploration)\n",
    "- Process 2: Updates Target parameters (slower than Process 1 and 3, like every 10k iterations), copies $\\phi$ into $\\phi'$, with $\\phi'$ being the current target\n",
    "- Process 3: Actuall Training, fetch data from buffer, update our Q function $\\phi$\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, n_observations, n_actions):\n",
    "        super(DQN, self).__init__()\n",
    "        self.layer1 = nn.Linear(n_observations, 128)\n",
    "        self.layer2 = nn.Linear(128, 128)\n",
    "        self.layer3 = nn.Linear(128, n_actions)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        return self.layer3(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First enviroment: pendulum\n",
    "--\n",
    "\n",
    "Action Space: Box(-2.0, 2.0, (1,), float32)\n",
    "\n",
    "Observation Space: Box([-1. -1. -8.], [1. 1. 8.], (3,), float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE is the number of transitions sampled from the replay buffer\n",
    "# GAMMA is the discount factor as mentioned in the previous section\n",
    "# TAU is the update rate of the target network\n",
    "# LR is the learning rate of the ``AdamW`` optimizer\n",
    "BATCH_SIZE = 128\n",
    "CAPACITY = 10000 # Capacity of Replay Memory Buffer\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.9 # Epsilon Greedy with decay rate based on steps taken for exploration\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 1000\n",
    "TAU = 0.005 # Instead of doing a hard update from the policy network to the target network, we do a soft update every iteration\n",
    "LR = 1e-4\n",
    "\n",
    "\n",
    "env = gym.make(\"Pendulum-v1\")\n",
    "# Discretized Action Space\n",
    "action_range = (env.action_space.low[0], env.action_space.high[0])\n",
    "n_actions = 10\n",
    "actions = np.linspace(action_range[0], action_range[1], n_actions)\n",
    "\n",
    "# Get the number of state observations\n",
    "state, info = env.reset()\n",
    "n_observations = len(state)\n",
    "\n",
    "policy_net = DQN(n_observations, n_actions).to(device)\n",
    "target_net = DQN(n_observations, n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
    "memory = ReplayMemory(CAPACITY)\n",
    "\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return the largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return policy_net(state).max(1).indices.view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([np.digitize(env.action_space.sample(), actions)], device=device, dtype=torch.long)\n",
    "\n",
    "episode_durations = []\n",
    "\n",
    "\n",
    "def plot_durations(show_result=False):\n",
    "    plt.figure(1)\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    if show_result:\n",
    "        plt.title('Result')\n",
    "    else:\n",
    "        plt.clf()\n",
    "        plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        if not show_result:\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        else:\n",
    "            display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\nabla_{\\theta_i}L_i(\\theta_i) = \\mathbb{E}_{s, a \\sim p(\\cdot);s'\\sim \\epsilon} \\big[\\big(r+\\gamma \\max_{a'} Q(s', a';\\theta_{i-1})-Q(s,a;\\theta_i)\\big)\\nabla_{\\theta_i}(s,a;\\theta_i) \\big]$\n",
    "\n",
    "we want to minimize: (loss_function):\n",
    "\n",
    "$(y_j − Q(\\phi_j, a_j; \\theta))²$\n",
    "\n",
    "where\n",
    "\n",
    "$\n",
    "\\text{Set} \\ y = \\begin{cases}\n",
    "r_j, & \\text{for terminal} \\ \\phi_{j+1} \\\\\n",
    "r_j+\\gamma \\ max_{a^{'}}Q(\\phi_{j+1}, a';\\theta), & \\text{for non-terminal } \\ \\phi_{j+1}\n",
    "\\end{cases}\n",
    "$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(Q_values, target_Q_values, rewards, done):\n",
    "    # Calculate the target values\n",
    "    if done:\n",
    "        y = rewards\n",
    "    else:\n",
    "        y = rewards + GAMMA * torch.max(target_Q_values, dim=-1)[0] \n",
    "\n",
    "    # Calculate the temporal difference error\n",
    "    TD_error = y - Q_values.gather(1, actions)\n",
    "\n",
    "    # Square the TD error\n",
    "    squared_TD_error = TD_error ** 2\n",
    "\n",
    "    # Calculate the mean squared TD error\n",
    "    loss = torch.mean(squared_TD_error)\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1).values\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    with torch.no_grad():\n",
    "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1).values\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute loss\n",
    "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "    \n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # In-place gradient clipping\n",
    "    torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4] [-0.5389951] [-2.         -1.55555556 -1.11111111 -0.66666667 -0.22222222  0.22222222\n",
      "  0.66666667  1.11111111  1.55555556  2.        ]\n",
      "[-0.22222222]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-0.99995065, -0.00993714, -0.764637  ], dtype=float32),\n",
       " -9.6176473218693,\n",
       " False,\n",
       " False,\n",
       " {})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state, info = env.reset()\n",
    "sampled_value = env.action_space.sample()\n",
    "mapped_action = np.digitize(sampled_value, actions)\n",
    "print(mapped_action, sampled_value, actions)\n",
    "print(actions[mapped_action])\n",
    "env.step(actions[mapped_action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    num_episodes = 600\n",
    "else:\n",
    "    num_episodes = 50\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and get its state\n",
    "    state, info = env.reset()\n",
    "    state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    for t in count():\n",
    "        action = select_action(state) # change to select_action(state)\n",
    "        # print(action.item())\n",
    "        observation, reward, terminated, truncated, _ = env.step([actions[action.item()]])\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "        done = terminated or truncated\n",
    "\n",
    "        if terminated:\n",
    "            next_state = None\n",
    "        else:\n",
    "            next_state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the policy network)\n",
    "        optimize_model()\n",
    "\n",
    "        # Soft update of the target network's weights\n",
    "        # θ′ ← τ θ + (1 −τ )θ′\n",
    "        target_net_state_dict = target_net.state_dict()\n",
    "        policy_net_state_dict = policy_net.state_dict()\n",
    "        for key in policy_net_state_dict:\n",
    "            target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
    "        target_net.load_state_dict(target_net_state_dict)\n",
    "\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            plot_durations()\n",
    "            break\n",
    "\n",
    "print('Complete')\n",
    "plot_durations(show_result=True)\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
